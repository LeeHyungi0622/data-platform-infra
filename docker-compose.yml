
# /*******************************************************************
# *
# * Copyright         : 2024/04/18 이현기(Lee Hyungi)
# * File Name         : docker-compose.yml
# * Description       : 해당 파일은 Hadoop EcoSystem의 각 서비스들을 올리기 위해 
#                       필요한 docker-compose.yml 파일입니다.
# *                    
# * Revision History  :
# * Date              Author           Comments
#   2024/04/17  이현기 (Lee Hyungi)     초기 작업 착수
# * ------------------------------------------------------------------
# * 2024/04/17  이현기 (Lee Hyungi)    Zookeeper, Kafka 서비스 작성
# * ------------------------------------------------------------------
# * 2024/04/18  이현기 (Lee Hyungi)    HDFS 서비스 작성 (NN 2개, DN 3개)
# *                                  MetaStore 서비스 작성
# *                                  HiveServer01/02 서비스 작성
# * ------------------------------------------------------------------
# * 
# /******************************************************************/

version: "3"
services:

# Zookeeper 컨테이너 정의 -- START
  zoo-1:
    image: zookeeper
    restart: always
    hostname: zoo-1
    ports:
      - 2181:2181
    environment:
      ZOO_MY_ID: 1
      ZOO_SERVERS: server.1=zoo-1:2888:3888;2181 server.2=zoo-2:2888:3888;2181 server.3=zoo-3:2888:3888;2181

  zoo-2:
    image: zookeeper
    restart: always
    hostname: zoo-2
    ports:
      - 2182:2181
    environment:
      ZOO_MY_ID: 2
      ZOO_SERVERS: server.1=zoo-1:2888:3888;2181 server.2=zoo-2:2888:3888;2181 server.3=zoo-3:2888:3888;2181

  zoo-3:
    image: zookeeper
    restart: always
    hostname: zoo-3
    ports:
      - 2183:2181
    environment:
      ZOO_MY_ID: 3
      ZOO_SERVERS: server.1=zoo-1:2888:3888;2181 server.2=zoo-2:2888:3888;2181 server.3=zoo-3:2888:3888;2181
# Zookeeper 컨테이너 정의 -- END

# Kafka 컨테이너 정의 -- START
  kafka-1:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-1
    ports:
      - 29092:29092
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zoo-1:2181,zoo-2:2182,zoo-3:2183
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  
  kafka-2:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-2
    ports:
      - 39092:39092
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: zoo-1:2181,zoo-2:2182,zoo-3:2183
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9092,PLAINTEXT_HOST://localhost:39092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  
  kafka-3:
    image: confluentinc/cp-kafka:7.4.4
    container_name: kafka-3
    ports:
      - 49092:49092
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: zoo-1:2181,zoo-2:2182,zoo-3:2183
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9092,PLAINTEXT_HOST://localhost:49092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
# Kafka 컨테이너 정의 -- START

# HDFS 컨테이너 정의 (NN, DN) -- START
  nn01:
    image: hadoop_base:latest
    container_name: nn01
    hostname: nn01
    entrypoint: /entrypoint.sh namenode
    ports:
      - 50070:50070
      - 8088:8088
    # volumes:
    #   - hadoop_namenode:/opt/hadoop/dfs/namenode
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
  nn02:
    image: hadoop_base:latest
    container_name: nn02
    hostname: nn02
    entrypoint: /entrypoint.sh secondarynamenode
    ports:
      - 50080:50070
      - 8089:8088
    # volumes:
    #   - hadoop_namenode:/opt/hadoop/dfs/namesecondary
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
  dn01:
    image: hadoop_base:latest
    container_name: dn01
    hostname: dn01
    entrypoint: /entrypoint.sh zkdatanode
    # volumes:
    #   - hadoop_first_datanode:/opt/hadoop/dfs/datanode
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
  dn02:
    image: hadoop_base:latest
    container_name: dn02
    hostname: dn02
    entrypoint: /entrypoint.sh datanode
    # volumes:
    #   - hadoop_second_datanode:/opt/hadoop/dfs/datanode
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
  dn03:
    image: hadoop_base:latest
    container_name: dn03
    hostname: dn03
    entrypoint: /entrypoint.sh datanode
    # volumes:
    #   - hadoop_third_datanode:/opt/hadoop/dfs/datanode
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
# HDFS 컨테이너 정의 (NN, DN) -- END

# Metadata 컨테이너 정의 (metastore) -- START
  metastore:
    image: postgres:15.6
    container_name: metastore
    restart: always
    shm_size: 128mb
    environment:
      POSTGRES_PASSWORD: root
    ports:
      - 15432:5432
    # volumes:
    #   - hive_metastore:/var/lib/postgresql/data
# Metadata 컨테이너 정의 (metastore) -- END

# Hive 컨테이너 정의 (HS01, HS02) -- START
  hs01:
    image: hive_base:latest
    container_name: hs01
    hostname: hs01
    command: /entrypoint.sh hs2
    ports:
      - 10000:10000
    # volumes:
    #   - hive_first_server:/opt/hive/warehouse
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
      - nn01
      - nn02
      - dn01
      - dn02
      - dn03
      - metastore
  hs02:
    image: hive_base:latest
    container_name: hs02
    hostname: hs02
    command: /entrypoint.sh hs2
    ports:
      - 10001:10000
    # volumes:
    #   - hive_second_server:/opt/hive/warehouse
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
      - nn01
      - nn02
      - dn01
      - dn02
      - dn03
      - metastore
# Hive 컨테이너 정의 (HS01, HS02) -- END

# HBase 컨테이너 정의 (hbase-master, hbase-region) -- START
  hbase-master:
    image: hbase-master-2.5.0
    container_name: hbase-master
    hostname: hbase-master
    env_file:
      - ./hbase-with-phoenix.env
    environment:
      SERVICE_PRECONDITION: "nn01:50070 nn02:50080 zoo-1:2181 zoo-2:2182 zoo-3:2183"
    command:
      - /opt/hbase-2.5.0/bin/hbase master start
    ports:
      - 16010:16010
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
      - nn01
      - nn02
      - dn01
      - dn02
      - dn03

  hregion-region:
    image: hbase-regionserver-2.5.0
    container_name: hbase-regionserver
    hostname: hbase-regionserver
    env_file:
      - ./hbase-with-phoenix.env
    environment:
      SERVICE_PRECONDITION: "nn01:50070 nn02:50080 zoo-1:2181 zoo-2:2182 zoo-3:2183 hbase-master:16010"
    command:
      - /opt/hbase-2.5.0/bin/hbase regionserver start
    ports:
      - 16020:16020
      - 16030:16030
    depends_on:
      - zoo-1
      - zoo-2
      - zoo-3
      - nn01
      - nn02
      - dn01
      - dn02
      - dn03
      - hbase-master
# HBase 컨테이너 정의 (hbase-master, hbase-region) -- END

# Phoenix queryserver 컨테이너 정의 (queryserver-1) -- START
  queryserver:
    container_name: queryserver
    image: phoenix-5.2.0
    ports:
      - 8765:8765
    depends_on: 
      - zoo-1
      - zoo-2
      - zoo-3
      - nn01
      - nn02
      - dn01
      - dn02
      - dn03
      - hbase-master
      - hregion-region
    environment:
      - HBASE_ZOOKEEPER_QUORUM=zoo-1:2181
      - HADOOP_NAMENODE1_HOSTNAME=nn01
      - HBASE_HMASTER1_HOSTNAME=hbase-master
      - HBASE_REGIONSERVER1_HOSTNAME=hbase-regionserver
      - HBASE_ROOT_DIR=hdfs://nn01:8020/hbase
    command: bin/sqlline.py zoo-1,zoo-2,zoo-3:2181:/hbase 
# Phoenix queryserver 컨테이너 정의 (queryserver-1) -- END

# volumes 생성
# volumes:
#   hadoop_namenode:
#   hadoop_namesecondary:
#   hadoop_first_datanode:
#   hadoop_second_datanode:
#   hadoop_third_datanode:
#   hive_metastore:
#   hive_first_server:
#   hive_second_server: